{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Project1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TaraRasti/MITx/blob/main/Machine%20Learning%20with%20Python-From%20Linear%20Models%20to%20Deep%20Learning/Project1/Project1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rough-statistics"
      },
      "source": [
        "import numpy as np"
      ],
      "id": "rough-statistics",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "industrial-cycle"
      },
      "source": [
        "import random\n",
        "def get_order(n_samples):\n",
        "    try:\n",
        "        with open(str(n_samples) + '.txt') as fp:\n",
        "            line = fp.readline()\n",
        "            return list(map(int, line.split(',')))\n",
        "    except FileNotFoundError:\n",
        "        random.seed(1)\n",
        "        indices = list(range(n_samples))\n",
        "        random.shuffle(indices)\n",
        "        return indices"
      ],
      "id": "industrial-cycle",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "floppy-branch"
      },
      "source": [
        "def hinge_loss_single(feature_vector, label, theta, theta_0):\n",
        "    \"\"\"\n",
        "    Finds the hinge loss on a single data point given specific classification\n",
        "    parameters.\n",
        "\n",
        "    Args:\n",
        "        feature_vector - A numpy array describing the given data point.\n",
        "        label - A real valued number, the correct classification of the data\n",
        "            point.\n",
        "        theta - A numpy array describing the linear classifier.\n",
        "        theta_0 - A real valued number representing the offset parameter.\n",
        "\n",
        "\n",
        "    Returns: A real number representing the hinge loss associated with the\n",
        "    given data point and parameters.\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    if label*(np.inner(theta,feature_vector)+theta_0) <= 0:\n",
        "        loss = 1-(label*(np.inner(theta,feature_vector)+theta_0))\n",
        "    else:\n",
        "        loss = 0\n",
        "    return loss\n",
        "    raise NotImplementedError"
      ],
      "id": "floppy-branch",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "analyzed-detector"
      },
      "source": [
        "def hinge_loss_full(feature_matrix, labels, theta, theta_0):\n",
        "    \"\"\"\n",
        "    Finds the total hinge loss on a set of data given specific classification\n",
        "    parameters.\n",
        "\n",
        "    Args:\n",
        "        feature_matrix - A numpy matrix describing the given data. Each row\n",
        "            represents a single data point.\n",
        "        labels - A numpy array where the kth element of the array is the\n",
        "            correct classification of the kth row of the feature matrix.\n",
        "        theta - A numpy array describing the linear classifier.\n",
        "        theta_0 - A real valued number representing the offset parameter.\n",
        "\n",
        "\n",
        "    Returns: A real number representing the hinge loss associated with the\n",
        "    given dataset and parameters. This number should be the average hinge\n",
        "    loss across all of the points in the feature matrix.\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    loss = []\n",
        "    for i in range(feature_matrix.shape[0]):\n",
        "        if labels[i]*(np.inner(theta,feature_matrix[i])+theta_0) <= 0:\n",
        "            loss.append(1-(labels[i]*(np.inner(theta,feature_matrix[i])+theta_0)))\n",
        "        else:\n",
        "            loss.append(0)\n",
        "    return np.mean(loss)\n",
        "    raise NotImplementedError"
      ],
      "id": "analyzed-detector",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hungarian-fashion"
      },
      "source": [
        "# Perceptron Algorithm"
      ],
      "id": "hungarian-fashion"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "worst-warrant"
      },
      "source": [
        "def perceptron_single_step_update(\n",
        "        feature_vector,\n",
        "        label,\n",
        "        current_theta,\n",
        "        current_theta_0):\n",
        "    \"\"\"\n",
        "    Properly updates the classification parameter, theta and theta_0, on a\n",
        "    single step of the perceptron algorithm.\n",
        "\n",
        "    Args:\n",
        "        feature_vector - A numpy array describing a single data point.\n",
        "        label - The correct classification of the feature vector.\n",
        "        current_theta - The current theta being used by the perceptron\n",
        "            algorithm before this update.\n",
        "        current_theta_0 - The current theta_0 being used by the perceptron\n",
        "            algorithm before this update.\n",
        "\n",
        "    Returns: A tuple where the first element is a numpy array with the value of\n",
        "    theta after the current update has completed and the second element is a\n",
        "    real valued number with the value of theta_0 after the current updated has\n",
        "    completed.\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    if label*(np.inner(current_theta,feature_vector)+current_theta_0) <= 0:\n",
        "        current_theta += label*feature_vector\n",
        "        current_theta_0 += label\n",
        "    else:\n",
        "        current_theta = current_theta\n",
        "        current_theta_0 = current_theta_0\n",
        "        \n",
        "    return (current_theta, current_theta_0)\n",
        "    raise NotImplementedError"
      ],
      "id": "worst-warrant",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "historic-summit"
      },
      "source": [
        "def perceptron(feature_matrix, labels, T):\n",
        "    \"\"\"\n",
        "    Runs the full perceptron algorithm on a given set of data. Runs T\n",
        "    iterations through the data set, there is no need to worry about\n",
        "    stopping early.\n",
        "\n",
        "    NOTE: Please use the previously implemented functions when applicable.\n",
        "    Do not copy paste code from previous parts.\n",
        "\n",
        "    NOTE: Iterate the data matrix by the orders returned by get_order(feature_matrix.shape[0])\n",
        "\n",
        "    Args:\n",
        "        feature_matrix -  A numpy matrix describing the given data. Each row\n",
        "            represents a single data point.\n",
        "        labels - A numpy array where the kth element of the array is the\n",
        "            correct classification of the kth row of the feature matrix.\n",
        "        T - An integer indicating how many times the perceptron algorithm\n",
        "            should iterate through the feature matrix.\n",
        "\n",
        "    Returns: A tuple where the first element is a numpy array with the value of\n",
        "    theta, the linear classification parameter, after T iterations through the\n",
        "    feature matrix and the second element is a real number with the value of\n",
        "    theta_0, the offset classification parameter, after T iterations through\n",
        "    the feature matrix.\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    current_theta = np.zeros(feature_matrix.shape[1])\n",
        "    current_theta_0 = 0\n",
        "    for t in range(T):\n",
        "        for i in get_order(feature_matrix.shape[0]):\n",
        "            # Your code here\n",
        "            feature_vector = feature_matrix[i] \n",
        "            label = labels[i]\n",
        "            theta = perceptron_single_step_update(feature_vector, label, current_theta, current_theta_0)\n",
        "            current_theta = theta[0]\n",
        "            current_theta_0 = theta[1]\n",
        "            pass\n",
        "    return (current_theta, current_theta_0)\n",
        "    raise NotImplementedError\n",
        "\n"
      ],
      "id": "historic-summit",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exposed-victim"
      },
      "source": [
        "def average_perceptron(feature_matrix, labels, T):\n",
        "    \"\"\"\n",
        "    Runs the average perceptron algorithm on a given set of data. Runs T\n",
        "    iterations through the data set, there is no need to worry about\n",
        "    stopping early.\n",
        "\n",
        "    NOTE: Please use the previously implemented functions when applicable.\n",
        "    Do not copy paste code from previous parts.\n",
        "\n",
        "    NOTE: Iterate the data matrix by the orders returned by get_order(feature_matrix.shape[0])\n",
        "\n",
        "\n",
        "    Args:\n",
        "        feature_matrix -  A numpy matrix describing the given data. Each row\n",
        "            represents a single data point.\n",
        "        labels - A numpy array where the kth element of the array is the\n",
        "            correct classification of the kth row of the feature matrix.\n",
        "        T - An integer indicating how many times the perceptron algorithm\n",
        "            should iterate through the feature matrix.\n",
        "\n",
        "    Returns: A tuple where the first element is a numpy array with the value of\n",
        "    the average theta, the linear classification parameter, found after T\n",
        "    iterations through the feature matrix and the second element is a real\n",
        "    number with the value of the average theta_0, the offset classification\n",
        "    parameter, found after T iterations through the feature matrix.\n",
        "\n",
        "    Hint: It is difficult to keep a running average; however, it is simple to\n",
        "    find a sum and divide.\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    current_theta = np.zeros(feature_matrix.shape[1])\n",
        "    current_theta_0 = 0\n",
        "    THETA = []\n",
        "    THETA_0 = []\n",
        "    for t in range(T):\n",
        "        for i in get_order(feature_matrix.shape[0]):\n",
        "            feature_vector = feature_matrix[i] \n",
        "            label = labels[i]\n",
        "            theta = perceptron_single_step_update(feature_vector, label, current_theta, current_theta_0)\n",
        "            current_theta = theta[0]\n",
        "            current_theta_0 = theta[1]\n",
        "            THETA.append(current_theta)\n",
        "            THETA_0.append(current_theta_0)\n",
        "    return (np.mean(THETA, axis=0),np.mean(THETA_0))\n",
        "    raise NotImplementedError"
      ],
      "id": "exposed-victim",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "advisory-variable"
      },
      "source": [
        "#  Pegasos Algorithm"
      ],
      "id": "advisory-variable"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "closed-career"
      },
      "source": [
        "def pegasos_single_step_update(\n",
        "        feature_vector,\n",
        "        label,\n",
        "        L,\n",
        "        eta,\n",
        "        current_theta,\n",
        "        current_theta_0):\n",
        "    \"\"\"\n",
        "    Properly updates the classification parameter, theta and theta_0, on a\n",
        "    single step of the Pegasos algorithm\n",
        "\n",
        "    Args:\n",
        "        feature_vector - A numpy array describing a single data point.\n",
        "        label - The correct classification of the feature vector.\n",
        "        L - The lamba value being used to update the parameters.\n",
        "        eta - Learning rate to update parameters.\n",
        "        current_theta - The current theta being used by the Pegasos\n",
        "            algorithm before this update.\n",
        "        current_theta_0 - The current theta_0 being used by the\n",
        "            Pegasos algorithm before this update.\n",
        "\n",
        "    Returns: A tuple where the first element is a numpy array with the value of\n",
        "    theta after the current update has completed and the second element is a\n",
        "    real valued number with the value of theta_0 after the current updated has\n",
        "    completed.\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    if label * (np.inner(current_theta,feature_vector) + current_theta_0) <= 1:\n",
        "        current_theta = ((1 - (eta * L)) * current_theta) + ((eta * label) * feature_vector)\n",
        "        current_theta_0 += eta * label\n",
        "    else:\n",
        "        current_theta = ((1 - (eta * L)) * current_theta)\n",
        "        current_theta_0 = current_theta_0\n",
        "    return (current_theta, current_theta_0)\n",
        "    raise NotImplementedError\n",
        "\n"
      ],
      "id": "closed-career",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "serial-lottery"
      },
      "source": [
        "def pegasos(feature_matrix, labels, T, L):\n",
        "    \"\"\"\n",
        "    Runs the Pegasos algorithm on a given set of data. Runs T\n",
        "    iterations through the data set, there is no need to worry about\n",
        "    stopping early.\n",
        "\n",
        "    For each update, set learning rate = 1/sqrt(t),\n",
        "    where t is a counter for the number of updates performed so far (between 1\n",
        "    and nT inclusive).\n",
        "\n",
        "    NOTE: Please use the previously implemented functions when applicable.\n",
        "    Do not copy paste code from previous parts.\n",
        "\n",
        "    Args:\n",
        "        feature_matrix - A numpy matrix describing the given data. Each row\n",
        "            represents a single data point.\n",
        "        labels - A numpy array where the kth element of the array is the\n",
        "            correct classification of the kth row of the feature matrix.\n",
        "        T - An integer indicating how many times the algorithm\n",
        "            should iterate through the feature matrix.\n",
        "        L - The lamba value being used to update the Pegasos\n",
        "            algorithm parameters.\n",
        "\n",
        "    Returns: A tuple where the first element is a numpy array with the value of\n",
        "    the theta, the linear classification parameter, found after T\n",
        "    iterations through the feature matrix and the second element is a real\n",
        "    number with the value of the theta_0, the offset classification\n",
        "    parameter, found after T iterations through the feature matrix.\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    current_theta = np.zeros(feature_matrix.shape[1])\n",
        "    current_theta_0 = 0\n",
        "    count = 0\n",
        "    for t in range(T):\n",
        "        for i in get_order(feature_matrix.shape[0]):\n",
        "            count += 1\n",
        "            eta = 1/np.sqrt(count)\n",
        "            Theta = pegasos_single_step_update(feature_matrix[i], labels[i], L, eta, current_theta, current_theta_0)\n",
        "            current_theta = Theta[0]\n",
        "            current_theta_0 = Theta[1]\n",
        "    return (current_theta, current_theta_0)\n",
        "    raise NotImplementedError"
      ],
      "id": "serial-lottery",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "visible-correlation"
      },
      "source": [
        "# Classification "
      ],
      "id": "visible-correlation"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "municipal-malaysia"
      },
      "source": [
        "def classify(feature_matrix, theta, theta_0):\n",
        "    \"\"\"\n",
        "    A classification function that uses theta and theta_0 to classify a set of\n",
        "    data points.\n",
        "\n",
        "    Args:\n",
        "        feature_matrix - A numpy matrix describing the given data. Each row\n",
        "            represents a single data point.\n",
        "                theta - A numpy array describing the linear classifier.\n",
        "        theta - A numpy array describing the linear classifier.\n",
        "        theta_0 - A real valued number representing the offset parameter.\n",
        "\n",
        "    Returns: A numpy array of 1s and -1s where the kth element of the array is\n",
        "    the predicted classification of the kth row of the feature matrix using the\n",
        "    given theta and theta_0. If a prediction is GREATER THAN zero, it should\n",
        "    be considered a positive classification.\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    preds = np.inner(feature_matrix, theta) + theta_0\n",
        "    for i in range(len(preds)):\n",
        "        if preds[i] > np.finfo(float).eps:\n",
        "            preds[i] = 1\n",
        "        else:\n",
        "            preds[i] = -1\n",
        "    return preds\n",
        "    raise NotImplementedError"
      ],
      "id": "municipal-malaysia",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "declared-miller"
      },
      "source": [
        "def accuracy(preds, targets):\n",
        "    \"\"\"\n",
        "    Given length-N vectors containing predicted and target labels,\n",
        "    returns the percentage and number of correct predictions.\n",
        "    \"\"\"\n",
        "    return (preds == targets).mean()"
      ],
      "id": "declared-miller",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "competitive-diana"
      },
      "source": [
        "def classifier_accuracy(\n",
        "        classifier,\n",
        "        train_feature_matrix,\n",
        "        val_feature_matrix,\n",
        "        train_labels,\n",
        "        val_labels,\n",
        "        **kwargs):\n",
        "    \"\"\"\n",
        "    Trains a linear classifier and computes accuracy.\n",
        "    The classifier is trained on the train data. The classifier's\n",
        "    accuracy on the train and validation data is then returned.\n",
        "\n",
        "    Args:\n",
        "        classifier - A classifier function that takes arguments\n",
        "            (feature matrix, labels, **kwargs) and returns (theta, theta_0)\n",
        "        train_feature_matrix - A numpy matrix describing the training\n",
        "            data. Each row represents a single data point.\n",
        "        val_feature_matrix - A numpy matrix describing the validation\n",
        "            data. Each row represents a single data point.\n",
        "        train_labels - A numpy array where the kth element of the array\n",
        "            is the correct classification of the kth row of the training\n",
        "            feature matrix.\n",
        "        val_labels - A numpy array where the kth element of the array\n",
        "            is the correct classification of the kth row of the validation\n",
        "            feature matrix.\n",
        "        **kwargs - Additional named arguments to pass to the classifier\n",
        "            (e.g. T or L)\n",
        "\n",
        "    Returns: A tuple in which the first element is the (scalar) accuracy of the\n",
        "    trained classifier on the training data and the second element is the\n",
        "    accuracy of the trained classifier on the validation data.\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    theta = classifier(train_feature_matrix, train_labels, **kwargs)[0]\n",
        "    theta_0 = classifier(train_feature_matrix, train_labels, **kwargs)[1]\n",
        "    train_preds = classify(train_feature_matrix, theta, theta_0)\n",
        "    val_preds = classify(val_feature_matrix, theta, theta_0)\n",
        "    train_acc = accuracy(train_preds, train_labels)\n",
        "    val_acc = accuracy(val_preds, val_labels)\n",
        "    return (train_acc, val_acc)\n",
        "    raise NotImplementedError"
      ],
      "id": "competitive-diana",
      "execution_count": null,
      "outputs": []
    }
  ]
}